
========================================
Starting pipeline at 2024-09-28 11:53:48.266736
========================================

Running dataloader.py...
Running: python3 ./dataloader.py
Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/SleepSource/ (158 files) - Load labels True
<Info | 8 non-empty values
 bads: []
 ch_names: Fpz-Cz, Pz-Oz
 chs: 2 EEG
 custom_ref_applied: False
 highpass: 0.5 Hz
 lowpass: 100.0 Hz
 meas_date: 1991-09-26 15:00:00 UTC
 nchan: 2
 projs: []
 sfreq: 100.0 Hz
 subject_info: 2 items (dict)
>
Loaded total 90545 samples for subjects: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38]
Source mean: -2.175762164676705e-07, std: 1.6836217270029333e-05, min: -14.7172265485441, max: 12.426637935405019
Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/LeaderboardSleep/sleep_target/ (25 files) - Load labels True
<Info | 8 non-empty values
 bads: []
 ch_names: Fpz-Cz, Pz-Oz
 chs: 2 EEG
 custom_ref_applied: False
 highpass: 0.5 Hz
 lowpass: 100.0 Hz
 meas_date: 1990-03-13 15:09:00 UTC
 nchan: 2
 projs: []
 sfreq: 100.0 Hz
 subject_info: 2 items (dict)
>
Loaded total 15442 samples for subjects: [0 1 2 3 4 5]
Leadeboard target mean: 0.038902552623313796, std: 1.0560441229752748, min: -11.688042547053058, max: 12.010867582259191
Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/LeaderboardSleep/testing/ (25 files) - Load labels False
Loaded total 25748 samples for subjects: [ 6  7  8  9 10 11 12 13 14 15 16 17]
Leadeboard test mean: 0.014119353426048422, std: 0.8645048345254686, min: -11.985021370728651, max: 11.832680288053835
Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/finalSleep/sleep_target/ (20 files) - Load labels True
Loaded total 16568 samples for subjects: [0 1 2 3 4]
Final target mean: 0.023971523471475097, std: 0.8755512574787386, min: -11.866229841258413, max: 11.892076052788953
Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/finalSleep/testing/ (18 files) - Load labels False
Loaded total 25756 samples for subjects: [ 5  6  7  8  9 10 11 12 13]
Final test mean: 0.04296289931340894, std: 0.8598280113936251, min: -12.282000194404242, max: 11.713888758583598
0 (24043, 2, 3000)
1 (7941, 2, 3000)
2 (35983, 2, 3000)
3 (5247, 2, 3000)
4 (3057, 2, 3000)
5 (14274, 2, 3000)
Directory created: data/train
Directory created: data/validate
Directory created: data/test
Saved train data to data/train/data.npy and labels to data/train/labels.npy
Saved validate data to data/validate/data.npy and labels to data/validate/labels.npy
Saved test data to data/test/data.npy and labels to data/test/labels.npy
All variables saved successfully.


Running model: 1USleep
Running model_runner.py with argument: ./modelpy/1USleep.py
Running: python3 ./model_runner.py ./modelpy/1USleep.py
{0: 26.55180030925558, 1: 8.769604594654297, 2: 39.7393417274133, 3: 5.798542080848244, 4: 3.3797216699801194, 5: 15.760989617848464}
0 (2404, 2, 3000)
1 (794, 2, 3000)
2 (3598, 2, 3000)
3 (525, 2, 3000)
4 (306, 2, 3000)
5 (1427, 2, 3000)
Train data shape: (72436, 2, 3000)
Train labels shape: (72436,)
Validate data shape: (9054, 2, 3000)
Validate labels shape: (9054,)
Test data shape: (9055, 2, 3000)
Test labels shape: (9055,)
Total data size (number of samples): 90545
EEGClassifier(
  (base): BaseEEGClassifier(
    (usleep): USleep(
      (encoder): Sequential(
        (0): _EncoderBlock(
          (block_prepool): Sequential(
            (0): Conv1d(2, 6, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pad): ConstantPad1d(padding=(1, 1), value=0)
          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
        (1): _EncoderBlock(
          (block_prepool): Sequential(
            (0): Conv1d(6, 9, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pad): ConstantPad1d(padding=(1, 1), value=0)
          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
        (2): _EncoderBlock(
          (block_prepool): Sequential(
            (0): Conv1d(9, 11, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pad): ConstantPad1d(padding=(1, 1), value=0)
          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
        (3): _EncoderBlock(
          (block_prepool): Sequential(
            (0): Conv1d(11, 15, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pad): ConstantPad1d(padding=(1, 1), value=0)
          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
        (4): _EncoderBlock(
          (block_prepool): Sequential(
            (0): Conv1d(15, 20, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pad): ConstantPad1d(padding=(1, 1), value=0)
          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
        (5): _EncoderBlock(
          (block_prepool): Sequential(
            (0): Conv1d(20, 28, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pad): ConstantPad1d(padding=(1, 1), value=0)
          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
      (bottom): Sequential(
        (0): Conv1d(28, 40, kernel_size=(7,), stride=(1,), padding=(3,))
        (1): ELU(alpha=1.0)
        (2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (decoder): Sequential(
        (0): _DecoderBlock(
          (block_preskip): Sequential(
            (0): Upsample(scale_factor=2.0, mode='nearest')
            (1): Conv1d(40, 28, kernel_size=(2,), stride=(1,), padding=same)
            (2): ELU(alpha=1.0)
            (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (block_postskip): Sequential(
            (0): Conv1d(56, 28, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): _DecoderBlock(
          (block_preskip): Sequential(
            (0): Upsample(scale_factor=2.0, mode='nearest')
            (1): Conv1d(28, 20, kernel_size=(2,), stride=(1,), padding=same)
            (2): ELU(alpha=1.0)
            (3): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (block_postskip): Sequential(
            (0): Conv1d(40, 20, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): _DecoderBlock(
          (block_preskip): Sequential(
            (0): Upsample(scale_factor=2.0, mode='nearest')
            (1): Conv1d(20, 15, kernel_size=(2,), stride=(1,), padding=same)
            (2): ELU(alpha=1.0)
            (3): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (block_postskip): Sequential(
            (0): Conv1d(30, 15, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): _DecoderBlock(
          (block_preskip): Sequential(
            (0): Upsample(scale_factor=2.0, mode='nearest')
            (1): Conv1d(15, 11, kernel_size=(2,), stride=(1,), padding=same)
            (2): ELU(alpha=1.0)
            (3): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (block_postskip): Sequential(
            (0): Conv1d(22, 11, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (4): _DecoderBlock(
          (block_preskip): Sequential(
            (0): Upsample(scale_factor=2.0, mode='nearest')
            (1): Conv1d(11, 9, kernel_size=(2,), stride=(1,), padding=same)
            (2): ELU(alpha=1.0)
            (3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (block_postskip): Sequential(
            (0): Conv1d(18, 9, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): _DecoderBlock(
          (block_preskip): Sequential(
            (0): Upsample(scale_factor=2.0, mode='nearest')
            (1): Conv1d(9, 6, kernel_size=(2,), stride=(1,), padding=same)
            (2): ELU(alpha=1.0)
            (3): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (block_postskip): Sequential(
            (0): Conv1d(12, 6, kernel_size=(7,), stride=(1,), padding=same)
            (1): ELU(alpha=1.0)
            (2): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (clf): Sequential(
        (0): Conv1d(6, 6, kernel_size=(1,), stride=(1,))
        (1): Tanh()
        (2): AvgPool1d(kernel_size=(3000,), stride=(3000,), padding=(0,))
      )
      (final_layer): Sequential(
        (0): Conv1d(6, 5, kernel_size=(1,), stride=(1,))
        (1): ELU(alpha=1.0)
        (2): Conv1d(5, 5, kernel_size=(1,), stride=(1,))
        (3): Identity()
      )
    )
  )
  (fc): Linear(in_features=5, out_features=6, bias=True)
)
{
    "alpha": 0.01,
    "batch_size": 120,
    "device": "cuda",
    "epochs": 5,
    "lr": 0.001,
    "model_name": "eeg-classifier_seed-42",
    "num_workers": 2,
    "phase": "base",
    "seed": 42
}

###### PHASE 1 FINISHED ##########
Figure(640x480)

###### PHASE 2 FINISHED ########OUTPUT_FOLDER##
Figure(640x480)
train loss: 0.03504089788041987
train score: 0.8400442477876107
val loss: 0.031132205242389126
val score: 0.8559752595537884

###### PHASE 3 FINISHED ##########
Figure(640x480)
Training completed in: 00h 16m 52s
Figure(2200x600)
Figure(640x480)
Validation Accuracy: 0.8560

Running evaluator1USleep

Running model: 3cnn-trans-mlp
Running model_runner.py with argument: ./modelpy/3cnn-trans-mlp.py
Running: python3 ./model_runner.py ./modelpy/3cnn-trans-mlp.py
{0: 26.55180030925558, 1: 8.769604594654297, 2: 39.7393417274133, 3: 5.798542080848244, 4: 3.3797216699801194, 5: 15.760989617848464}
0 (2404, 2, 3000)
1 (794, 2, 3000)
2 (3598, 2, 3000)
3 (525, 2, 3000)
4 (306, 2, 3000)
5 (1427, 2, 3000)
Train data shape: (72436, 2, 3000)
Train labels shape: (72436,)
Validate data shape: (9054, 2, 3000)
Validate labels shape: (9054,)
Test data shape: (9055, 2, 3000)
Test labels shape: (9055,)
Total data size (number of samples): 90545
EEGClassifier(
  (cnn_layers): Sequential(
    (0): CNNBlock(
      (conv): Conv1d(2, 16, kernel_size=(7,), stride=(2,), padding=(3,))
      (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (1): CNNBlock(
      (conv): Conv1d(16, 32, kernel_size=(5,), stride=(2,), padding=(2,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (2): CNNBlock(
      (conv): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (3): CNNBlock(
      (conv): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
  )
  (transformer_layers): TransformerEncoder(
    (layers): ModuleList(
      (0-2): 3 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (linear1): Linear(in_features=128, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=128, bias=True)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (mlp): Sequential(
    (0): Linear(in_features=24064, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=512, out_features=128, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=128, out_features=6, bias=True)
  )
)
Output shape: torch.Size([32, 6])
{
    "alpha": 0.01,
    "batch_size": 120,
    "device": "cuda",
    "epochs": 5,
    "lr": 0.001,
    "model_name": "eeg-classifier_seed-42",
    "num_workers": 2,
    "phase": "base",
    "seed": 42
}

###### PHASE 1 FINISHED ##########
Figure(640x480)

###### PHASE 2 FINISHED ########OUTPUT_FOLDER##
Figure(640x480)
train loss: 0.012980598174749837
train score: 0.9643559488692232
val loss: 0.001849204470329967
val score: 0.9991164126352993

###### PHASE 3 FINISHED ##########
Figure(640x480)
Training completed in: 00h 43m 24s
Figure(2200x600)
Figure(640x480)
Validation Accuracy: 0.9991

Running evaluator3cnn-trans-mlp

Running model: 6SleepStagerChambon2018
Running model_runner.py with argument: ./modelpy/6SleepStagerChambon2018.py
Running: python3 ./model_runner.py ./modelpy/6SleepStagerChambon2018.py
{0: 26.55180030925558, 1: 8.769604594654297, 2: 39.7393417274133, 3: 5.798542080848244, 4: 3.3797216699801194, 5: 15.760989617848464}
0 (2404, 2, 3000)
1 (794, 2, 3000)
2 (3598, 2, 3000)
3 (525, 2, 3000)
4 (306, 2, 3000)
5 (1427, 2, 3000)
Train data shape: (72436, 2, 3000)
Train labels shape: (72436,)
Validate data shape: (9054, 2, 3000)
Validate labels shape: (9054,)
Test data shape: (9055, 2, 3000)
Test labels shape: (9055,)
Total data size (number of samples): 90545
EEGClassifier(
  (base): BaseEEGClassifier(
    (sleep_stager): SleepStagerChambon2018(
      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))
      (feature_extractor): Sequential(
        (0): Conv2d(1, 8, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))
        (1): Identity()
        (2): ReLU()
        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)
        (4): Conv2d(8, 8, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))
        (5): Identity()
        (6): ReLU()
        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)
      )
      (final_layer): Sequential(
        (0): Dropout(p=0.25, inplace=False)
        (1): Linear(in_features=272, out_features=5, bias=True)
      )
    )
  )
  (fc): Linear(in_features=5, out_features=6, bias=True)
)
{
    "alpha": 0.01,
    "batch_size": 120,
    "device": "cuda",
    "epochs": 5,
    "lr": 0.001,
    "model_name": "eeg-classifier_seed-42",
    "num_workers": 2,
    "phase": "base",
    "seed": 42
}

###### PHASE 1 FINISHED ##########
Figure(640x480)

###### PHASE 2 FINISHED ########OUTPUT_FOLDER##
Figure(640x480)
train loss: 0.04219050494442999
train score: 0.8051376597836775
val loss: 0.03944156544381067
val score: 0.8209631102275238

###### PHASE 3 FINISHED ##########
Figure(640x480)
Training completed in: 00h 06m 55s
Figure(2200x600)
Figure(640x480)
Validation Accuracy: 0.8210

Running evaluator6SleepStagerChambon2018

Running model: 2residual
Running model_runner.py with argument: ./modelpy/2residual.py
Running: python3 ./model_runner.py ./modelpy/2residual.py
{0: 26.55180030925558, 1: 8.769604594654297, 2: 39.7393417274133, 3: 5.798542080848244, 4: 3.3797216699801194, 5: 15.760989617848464}
0 (2404, 2, 3000)
1 (794, 2, 3000)
2 (3598, 2, 3000)
3 (525, 2, 3000)
4 (306, 2, 3000)
5 (1427, 2, 3000)
Train data shape: (72436, 2, 3000)
Train labels shape: (72436,)
Validate data shape: (9054, 2, 3000)
Validate labels shape: (9054,)
Test data shape: (9055, 2, 3000)
Test labels shape: (9055,)
Total data size (number of samples): 90545
EEGClassifier(
  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): ResidualBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (se): SEBlock(
        (avg_pool): AdaptiveAvgPool1d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=64, out_features=4, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=4, out_features=64, bias=False)
          (3): Sigmoid()
        )
      )
      (shortcut): Sequential()
    )
    (1): ResidualBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (se): SEBlock(
        (avg_pool): AdaptiveAvgPool1d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=64, out_features=4, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=4, out_features=64, bias=False)
          (3): Sigmoid()
        )
      )
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): ResidualBlock(
      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (se): SEBlock(
        (avg_pool): AdaptiveAvgPool1d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=128, out_features=8, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=8, out_features=128, bias=False)
          (3): Sigmoid()
        )
      )
      (shortcut): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): ResidualBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (se): SEBlock(
        (avg_pool): AdaptiveAvgPool1d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=128, out_features=8, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=8, out_features=128, bias=False)
          (3): Sigmoid()
        )
      )
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): ResidualBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (se): SEBlock(
        (avg_pool): AdaptiveAvgPool1d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=256, out_features=16, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=16, out_features=256, bias=False)
          (3): Sigmoid()
        )
      )
      (shortcut): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): ResidualBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (se): SEBlock(
        (avg_pool): AdaptiveAvgPool1d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=256, out_features=16, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=16, out_features=256, bias=False)
          (3): Sigmoid()
        )
      )
      (shortcut): Sequential()
    )
  )
  (gru): GRU(256, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)
  (attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=128, out_features=6, bias=True)
  )
)
Output shape: torch.Size([32, 6])
{
    "alpha": 0.01,
    "batch_size": 120,
    "device": "cuda",
    "epochs": 5,
    "lr": 0.001,
    "model_name": "eeg-classifier_seed-42",
    "num_workers": 2,
    "phase": "base",
    "seed": 42
}

###### PHASE 1 FINISHED ##########
Figure(640x480)

###### PHASE 2 FINISHED ########OUTPUT_FOLDER##
Figure(640x480)
train loss: 0.021675168577812414
train score: 0.9107177974434612
val loss: 0.010136361209381568
val score: 0.9731610337972167

###### PHASE 3 FINISHED ##########
Figure(640x480)
Training completed in: 00h 39m 13s
Figure(2200x600)
Figure(640x480)
Validation Accuracy: 0.9732

Running evaluator2residual

Running model: 4winner
Running model_runner.py with argument: ./modelpy/4winner.py
Running: python3 ./model_runner.py ./modelpy/4winner.py
{0: 26.55180030925558, 1: 8.769604594654297, 2: 39.7393417274133, 3: 5.798542080848244, 4: 3.3797216699801194, 5: 15.760989617848464}
0 (2404, 2, 3000)
1 (794, 2, 3000)
2 (3598, 2, 3000)
3 (525, 2, 3000)
4 (306, 2, 3000)
5 (1427, 2, 3000)
Train data shape: (72436, 2, 3000)
Train labels shape: (72436,)
Validate data shape: (9054, 2, 3000)
Validate labels shape: (9054,)
Test data shape: (9055, 2, 3000)
Test labels shape: (9055,)
Total data size (number of samples): 90545
{
    "alpha": 0.01,
    "batch_size": 120,
    "device": "cuda",
    "epochs": 5,
    "lr": 0.001,
    "model_name": "eeg-classifier_seed-42",
    "num_workers": 2,
    "phase": "base",
    "seed": 42
}

###### PHASE 1 FINISHED ##########
Figure(640x480)

###### PHASE 2 FINISHED ########OUTPUT_FOLDER##
Figure(640x480)
train loss: 0.028292526334392287
train score: 0.870771878072763
val loss: 0.020494473730459026
val score: 0.912856196156395

###### PHASE 3 FINISHED ##########
Figure(640x480)
Training completed in: 00h 07m 56s
Figure(2200x600)
Figure(640x480)
Validation Accuracy: 0.9129

Running evaluator4winner

Running model: 5SleepStagerBlanco2020
Running model_runner.py with argument: ./modelpy/5SleepStagerBlanco2020.py
Running: python3 ./model_runner.py ./modelpy/5SleepStagerBlanco2020.py
{0: 26.55180030925558, 1: 8.769604594654297, 2: 39.7393417274133, 3: 5.798542080848244, 4: 3.3797216699801194, 5: 15.760989617848464}
0 (2404, 2, 3000)
1 (794, 2, 3000)
2 (3598, 2, 3000)
3 (525, 2, 3000)
4 (306, 2, 3000)
5 (1427, 2, 3000)
Train data shape: (72436, 2, 3000)
Train labels shape: (72436,)
Validate data shape: (9054, 2, 3000)
Validate labels shape: (9054,)
Test data shape: (9055, 2, 3000)
Test labels shape: (9055,)
Total data size (number of samples): 90545
EEGClassifier(
  (base): BaseEEGClassifier(
    (sleep_stager): SleepStagerBlanco2020(
      (feature_extractor): Sequential(
        (0): Conv2d(2, 20, kernel_size=(1, 7), stride=(1, 1), groups=2)
        (1): Identity()
        (2): ReLU()
        (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
        (4): Conv2d(20, 20, kernel_size=(1, 7), stride=(1, 1), groups=20)
        (5): Identity()
        (6): ReLU()
        (7): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
        (8): Conv2d(20, 20, kernel_size=(1, 5), stride=(1, 1), groups=20)
        (9): Identity()
        (10): ReLU()
        (11): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
        (12): Conv2d(20, 20, kernel_size=(1, 5), stride=(1, 1), groups=20)
        (13): Identity()
        (14): ReLU()
        (15): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
        (16): Conv2d(20, 20, kernel_size=(1, 5), stride=(1, 1), groups=20)
        (17): Identity()
        (18): ReLU()
        (19): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
        (20): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), groups=20)
        (21): Identity()
        (22): ReLU()
        (23): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
        (24): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), groups=20)
        (25): Identity()
        (26): ReLU()
        (27): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
      )
      (final_layer): Sequential(
        (0): Dropout(p=0.5, inplace=False)
        (1): Linear(in_features=400, out_features=5, bias=True)
        (2): LogSoftmax(dim=1)
      )
    )
  )
  (fc): Linear(in_features=5, out_features=6, bias=True)
)
{
    "alpha": 0.01,
    "batch_size": 120,
    "device": "cuda",
    "epochs": 5,
    "lr": 0.001,
    "model_name": "eeg-classifier_seed-42",
    "num_workers": 2,
    "phase": "base",
    "seed": 42
}

###### PHASE 1 FINISHED ##########
Figure(640x480)

###### PHASE 2 FINISHED ########OUTPUT_FOLDER##
Figure(640x480)
train loss: 0.0675625396139678
train score: 0.6349803343166175
val loss: 0.06285000166022464
val score: 0.6477799867461895

###### PHASE 3 FINISHED ##########
Figure(640x480)
Training completed in: 00h 05m 42s
Figure(2200x600)
Figure(640x480)
Validation Accuracy: 0.6478

Running evaluator5SleepStagerBlanco2020

Pipeline completed at 2024-09-28 13:56:35.199940
========================================

