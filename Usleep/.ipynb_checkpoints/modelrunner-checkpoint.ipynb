{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "191235c5-bffa-4331-9fcd-c107857a70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepak/miniconda3/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 26.55180030925558, 1: 8.769604594654297, 2: 39.7393417274133, 3: 5.798542080848244, 4: 3.3797216699801194, 5: 15.760989617848464}\n",
      "0 (2404, 2, 3000)\n",
      "1 (794, 2, 3000)\n",
      "2 (3598, 2, 3000)\n",
      "3 (525, 2, 3000)\n",
      "4 (306, 2, 3000)\n",
      "5 (1427, 2, 3000)\n",
      "Train data shape: (72436, 2, 3000)\n",
      "Train labels shape: (72436,)\n",
      "Validate data shape: (9054, 2, 3000)\n",
      "Validate labels shape: (9054,)\n",
      "Test data shape: (9055, 2, 3000)\n",
      "Test labels shape: (9055,)\n",
      "Total data size (number of samples): 90545\n",
      "EEGClassifier(\n",
      "  (base): BaseEEGClassifier(\n",
      "    (usleep): USleep(\n",
      "      (encoder): Sequential(\n",
      "        (0): _EncoderBlock(\n",
      "          (block_prepool): Sequential(\n",
      "            (0): Conv1d(2, 6, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (pad): ConstantPad1d(padding=(1, 1), value=0)\n",
      "          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): _EncoderBlock(\n",
      "          (block_prepool): Sequential(\n",
      "            (0): Conv1d(6, 9, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (pad): ConstantPad1d(padding=(1, 1), value=0)\n",
      "          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): _EncoderBlock(\n",
      "          (block_prepool): Sequential(\n",
      "            (0): Conv1d(9, 11, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (pad): ConstantPad1d(padding=(1, 1), value=0)\n",
      "          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (3): _EncoderBlock(\n",
      "          (block_prepool): Sequential(\n",
      "            (0): Conv1d(11, 15, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (pad): ConstantPad1d(padding=(1, 1), value=0)\n",
      "          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (4): _EncoderBlock(\n",
      "          (block_prepool): Sequential(\n",
      "            (0): Conv1d(15, 20, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (pad): ConstantPad1d(padding=(1, 1), value=0)\n",
      "          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (5): _EncoderBlock(\n",
      "          (block_prepool): Sequential(\n",
      "            (0): Conv1d(20, 28, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (pad): ConstantPad1d(padding=(1, 1), value=0)\n",
      "          (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (bottom): Sequential(\n",
      "        (0): Conv1d(28, 40, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (decoder): Sequential(\n",
      "        (0): _DecoderBlock(\n",
      "          (block_preskip): Sequential(\n",
      "            (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "            (1): Conv1d(40, 28, kernel_size=(2,), stride=(1,), padding=same)\n",
      "            (2): ELU(alpha=1.0)\n",
      "            (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (block_postskip): Sequential(\n",
      "            (0): Conv1d(56, 28, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): _DecoderBlock(\n",
      "          (block_preskip): Sequential(\n",
      "            (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "            (1): Conv1d(28, 20, kernel_size=(2,), stride=(1,), padding=same)\n",
      "            (2): ELU(alpha=1.0)\n",
      "            (3): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (block_postskip): Sequential(\n",
      "            (0): Conv1d(40, 20, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): _DecoderBlock(\n",
      "          (block_preskip): Sequential(\n",
      "            (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "            (1): Conv1d(20, 15, kernel_size=(2,), stride=(1,), padding=same)\n",
      "            (2): ELU(alpha=1.0)\n",
      "            (3): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (block_postskip): Sequential(\n",
      "            (0): Conv1d(30, 15, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (3): _DecoderBlock(\n",
      "          (block_preskip): Sequential(\n",
      "            (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "            (1): Conv1d(15, 11, kernel_size=(2,), stride=(1,), padding=same)\n",
      "            (2): ELU(alpha=1.0)\n",
      "            (3): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (block_postskip): Sequential(\n",
      "            (0): Conv1d(22, 11, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (4): _DecoderBlock(\n",
      "          (block_preskip): Sequential(\n",
      "            (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "            (1): Conv1d(11, 9, kernel_size=(2,), stride=(1,), padding=same)\n",
      "            (2): ELU(alpha=1.0)\n",
      "            (3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (block_postskip): Sequential(\n",
      "            (0): Conv1d(18, 9, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (5): _DecoderBlock(\n",
      "          (block_preskip): Sequential(\n",
      "            (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "            (1): Conv1d(9, 6, kernel_size=(2,), stride=(1,), padding=same)\n",
      "            (2): ELU(alpha=1.0)\n",
      "            (3): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (block_postskip): Sequential(\n",
      "            (0): Conv1d(12, 6, kernel_size=(7,), stride=(1,), padding=same)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (clf): Sequential(\n",
      "        (0): Conv1d(6, 6, kernel_size=(1,), stride=(1,))\n",
      "        (1): Tanh()\n",
      "        (2): AvgPool1d(kernel_size=(3000,), stride=(3000,), padding=(0,))\n",
      "      )\n",
      "      (final_layer): Sequential(\n",
      "        (0): Conv1d(6, 5, kernel_size=(1,), stride=(1,))\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Conv1d(5, 5, kernel_size=(1,), stride=(1,))\n",
      "        (3): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=5, out_features=6, bias=True)\n",
      ")\n",
      "{\n",
      "    \"alpha\": 0.01,\n",
      "    \"batch_size\": 120,\n",
      "    \"device\": \"cuda\",\n",
      "    \"epochs\": 1,\n",
      "    \"lr\": 0.001,\n",
      "    \"model_name\": \"eeg-classifier_seed-42\",\n",
      "    \"num_workers\": 2,\n",
      "    \"phase\": \"base\",\n",
      "    \"seed\": 42\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Train loss: 0.1738, score: 0.0556:   3%|██▎                                                              | 21/603 [00:01<00:42, 13.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 747\u001b[0m\n\u001b[1;32m    744\u001b[0m seed_everything(args\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# Call the new function that tracks time and saves the model using the model file name from the argument\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m \u001b[43mrun_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupervised_mixup_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupervised_mixup_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Append the arguments to the array for later reference\u001b[39;00m\n\u001b[1;32m    750\u001b[0m args_array\u001b[38;5;241m.\u001b[39mappend(args)\n",
      "Cell \u001b[0;32mIn[13], line 590\u001b[0m, in \u001b[0;36mrun_and_save_model\u001b[0;34m(args, model_name, source_data, source_labels, target_data, target_labels, test_data, test_labels, mixup_data, supervised_mixup_data)\u001b[0m\n\u001b[1;32m    587\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# Call the existing supervised_run function (no modifications)\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m \u001b[43msupervised_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixup_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupervised_mixup_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupervised_mixup_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# Calculate and save training time\u001b[39;00m\n\u001b[1;32m    593\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[13], line 491\u001b[0m, in \u001b[0;36msupervised_run\u001b[0;34m(args, model, train_data, train_labels, target_data, target_labels, test_data, mixup_data, supervised_mixup_data)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m### USE ONLY SOURCE DATA ###\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m    489\u001b[0m args\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 491\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmixup_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixup_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# validate\u001b[39;00m\n\u001b[1;32m    497\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mbest_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mget_model_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[13], line 401\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(args, model, train_data, train_labels, valid_data, valid_labels, train_weights, sample_rate, use_scheduler, history, mixup_data, supervised_mixup_data, mixup_idx, mixup_rate)\u001b[0m\n\u001b[1;32m    398\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 401\u001b[0m     _, _, train_score, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     _, _, valid_score, valid_loss \u001b[38;5;241m=\u001b[39m validate_model(args, model, valid_data, valid_labels, show_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    404\u001b[0m     history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[13], line 216\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, loader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m eeg \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    214\u001b[0m target \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 216\u001b[0m lds \u001b[38;5;241m=\u001b[39m \u001b[43mvat_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meeg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m output \u001b[38;5;241m=\u001b[39m model(eeg)\n\u001b[1;32m    218\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target) \u001b[38;5;241m+\u001b[39m args\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m lds\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 185\u001b[0m, in \u001b[0;36mVATLoss.forward\u001b[0;34m(self, model, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mip):\n\u001b[1;32m    184\u001b[0m     d\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[0;32m--> 185\u001b[0m     pred_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     logp_hat \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(pred_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    187\u001b[0m     adv_distance \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mkl_div(logp_hat, pred, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/5cd1329d-6ad0-4c91-904e-ba21c872357b/Deepak/Students/Susmit_23CS60R75/model_final/Usleep/modelpy/eeg_model.py:44\u001b[0m, in \u001b[0;36mEEGClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/mnt/5cd1329d-6ad0-4c91-904e-ba21c872357b/Deepak/Students/Susmit_23CS60R75/model_final/Usleep/modelpy/eeg_model.py:40\u001b[0m, in \u001b[0;36mEEGClassifier.features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeatures\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/5cd1329d-6ad0-4c91-904e-ba21c872357b/Deepak/Students/Susmit_23CS60R75/model_final/Usleep/modelpy/eeg_model.py:29\u001b[0m, in \u001b[0;36mBaseEEGClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/braindecode/models/usleep.py:318\u001b[0m, in \u001b[0;36mUSleep.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    316\u001b[0m residuals \u001b[38;5;241m=\u001b[39m residuals[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# flip order\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m up, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder, residuals):\n\u001b[0;32m--> 318\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# classifier\u001b[39;00m\n\u001b[1;32m    321\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/braindecode/models/usleep.py:100\u001b[0m, in \u001b[0;36m_DecoderBlock.forward\u001b[0;34m(self, x, residual)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, residual):\n\u001b[0;32m--> 100\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_preskip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_skip_connection:\n\u001b[1;32m    102\u001b[0m         x, residual \u001b[38;5;241m=\u001b[39m _crop_tensors_to_match(x, residual, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# in case of mismatch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/activation.py:532\u001b[0m, in \u001b[0;36mELU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:1593\u001b[0m, in \u001b[0;36melu\u001b[0;34m(input, alpha, inplace)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1593\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# !mkdir /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/Usleep/outputs\n",
    "\n",
    "OUTPUT_FOLDER='/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/Usleep/outputs'\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import mne\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import contextlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import time\n",
    "import importlib.util\n",
    "import importlib.util\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "\n",
    "\"\"\"### args\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def add_noise(data):\n",
    "    if np.random.rand() > 0.5:\n",
    "        data += np.random.normal(0, 0.01, (data.shape))\n",
    "    return data\n",
    "\n",
    "def handle_mixup(idx, data, label, mixup_data, supervised_mixup_data, mixup_idx, mixup_rate):\n",
    "    mixup_data = mixup_data\n",
    "    # use supervised mixup data if available\n",
    "    if supervised_mixup_data is not None:\n",
    "        mixup_data = supervised_mixup_data[label]\n",
    "    # if mixup condition is set and id is not mixable\n",
    "    if mixup_idx is not None and not mixup_idx[idx]:\n",
    "        mixup_data = None\n",
    "    # do mixup if available\n",
    "    if mixup_data is not None:\n",
    "        data = mixup(data, mixup_data, mixup_rate)\n",
    "\n",
    "    return data\n",
    "\n",
    "def mixup(data, mixup_data, mixup_rate):\n",
    "    mixup_rate = np.random.rand() * mixup_rate\n",
    "    idx = np.random.randint(0, len(mixup_data))\n",
    "    return (1-mixup_rate)*data + mixup_rate*mixup_data[idx]\n",
    "\n",
    "class SleepDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels, transform=None, mixup_data=None, supervised_mixup_data=None, mixup_idx=None, mixup_rate=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        self.supervised_mixup_data = supervised_mixup_data\n",
    "        self.mixup_data = mixup_data\n",
    "        self.mixup_idx = mixup_idx\n",
    "        self.mixup_rate = mixup_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx].astype(np.int64)\n",
    "        else:\n",
    "            label = -1\n",
    "\n",
    "        ### DATA AUGMENTATION ###\n",
    "        data = handle_mixup(idx, data, label, self.mixup_data, self.supervised_mixup_data, self.mixup_idx, self.mixup_rate)\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        ### END DATA AUGMENTATION ###\n",
    "\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "        return {\"eeg\": data, \"label\": label}\n",
    "\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha: int = 1,\n",
    "        gamma: int = 2,\n",
    "        logits: bool = True,\n",
    "        reduce: bool = True,\n",
    "        ls: float = 0.05,\n",
    "        classes: int = 6,\n",
    "    ):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "        self.ls = ls\n",
    "        self.classes = classes\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = F.one_hot(targets, num_classes=6)\n",
    "\n",
    "        if self.ls is not None:\n",
    "            targets = (1 - self.ls) * targets + self.ls / self.classes\n",
    "\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction=\"none\")\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _disable_tracking_bn_stats(model):\n",
    "\n",
    "    def switch_attr(m):\n",
    "        if hasattr(m, 'track_running_stats'):\n",
    "            m.track_running_stats ^= True\n",
    "\n",
    "    model.apply(switch_attr)\n",
    "    yield\n",
    "    model.apply(switch_attr)\n",
    "\n",
    "\n",
    "def _l2_normalize(d):\n",
    "    d_reshaped = d.view(d.shape[0], -1, *(1 for _ in range(d.dim() - 2)))\n",
    "    d /= torch.norm(d_reshaped, dim=1, keepdim=True) + 1e-8\n",
    "    return d\n",
    "\n",
    "\n",
    "class VATLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, xi=10.0, eps=1.0, ip=1):\n",
    "        super(VATLoss, self).__init__()\n",
    "        self.xi = xi\n",
    "        self.eps = eps\n",
    "        self.ip = ip\n",
    "\n",
    "    def forward(self, model, x):\n",
    "        with torch.no_grad():\n",
    "            pred = F.softmax(model(x), dim=1)\n",
    "\n",
    "        # prepare random unit tensor\n",
    "        d = torch.rand(x.shape).sub(0.5).to(x.device)\n",
    "        d = _l2_normalize(d)\n",
    "\n",
    "        with _disable_tracking_bn_stats(model):\n",
    "            # calc adversarial direction\n",
    "            for _ in range(self.ip):\n",
    "                d.requires_grad_()\n",
    "                pred_hat = model(x + self.xi * d)\n",
    "                logp_hat = F.log_softmax(pred_hat, dim=1)\n",
    "                adv_distance = F.kl_div(logp_hat, pred, reduction='batchmean')\n",
    "                adv_distance.backward()\n",
    "                d = _l2_normalize(d.grad)\n",
    "                model.zero_grad()\n",
    "\n",
    "            # calc LDS\n",
    "            r_adv = d * self.eps\n",
    "            pred_hat = model(x + r_adv)\n",
    "            logp_hat = F.log_softmax(pred_hat, dim=1)\n",
    "            lds = F.kl_div(logp_hat, pred, reduction='batchmean')\n",
    "\n",
    "        return lds\n",
    "\n",
    "def train_epoch(args, model, loader, criterion, optimizer, scheduler, epoch):\n",
    "    losses = []\n",
    "    targets_all = []\n",
    "    outputs_all = []\n",
    "\n",
    "    vat_loss = VATLoss(xi=10.0, eps=1.0, ip=1)\n",
    "\n",
    "    model.train()\n",
    "    t = tqdm(loader)\n",
    "\n",
    "    for i, sample in enumerate(t):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        eeg = sample[\"eeg\"].to(args.device)\n",
    "        target = sample[\"label\"].to(args.device)\n",
    "\n",
    "        lds = vat_loss(model, eeg)\n",
    "        output = model(eeg)\n",
    "        loss = criterion(output, target) + args.alpha * lds\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        target = target.cpu().numpy()\n",
    "        output = output.detach().cpu().numpy()\n",
    "\n",
    "        targets_all.extend(target)\n",
    "        outputs_all.extend(output)\n",
    "\n",
    "        output_loss = np.mean(losses)\n",
    "        output_score = np.mean(targets_all == np.argmax(outputs_all, axis=1))\n",
    "\n",
    "        t.set_description(\n",
    "            f\"Epoch {epoch}/{args.epochs} - Train loss: {output_loss:0.4f}, score: {output_score:0.4f}\"\n",
    "        )\n",
    "\n",
    "    return targets_all, outputs_all, output_score, output_loss\n",
    "\n",
    "\n",
    "def validate(args, model, loader, criterion, desc=\"Valid\"):\n",
    "    losses = []\n",
    "    targets_all = []\n",
    "    outputs_all = []\n",
    "\n",
    "    t = tqdm(loader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(t):\n",
    "            eeg = sample[\"eeg\"].to(args.device)\n",
    "            target = sample[\"label\"].to(args.device)\n",
    "\n",
    "            output = model(eeg)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            targets_all.extend(target.cpu().numpy())\n",
    "            outputs_all.extend(output.detach().cpu().numpy())\n",
    "\n",
    "            output_loss = np.mean(losses)\n",
    "            output_score = np.mean(targets_all == np.argmax(outputs_all, axis=1))\n",
    "\n",
    "            t.set_description(\n",
    "                f\"\\t  - {desc} loss: {output_loss:0.4f}, score: {output_score:0.4f}\"\n",
    "            )\n",
    "\n",
    "    return targets_all, outputs_all, output_score, output_loss\n",
    "\n",
    "\n",
    "def predict(args, model, loader):\n",
    "    outputs_all = []\n",
    "\n",
    "    t = tqdm(loader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(t):\n",
    "            eeg = sample[\"eeg\"].to(args.device)\n",
    "\n",
    "            output = model(eeg)\n",
    "            outputs_all.extend(output.detach().cpu().numpy())\n",
    "    return outputs_all\n",
    "\n",
    "\"\"\"## model\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from braindecode.models import USleep\n",
    "\n",
    "def get_linear(in_features, out_features):\n",
    "    return nn.utils.weight_norm(nn.Linear(in_features, out_features))\n",
    "\n",
    "# class BaseEEGClassifier(nn.Module):\n",
    "#     def __init__(self, n_chans=2, sfreq=100, depth=6, n_time_filters=5,\n",
    "#                  complexity_factor=1.67, with_skip_connection=True, n_outputs=5,\n",
    "#                  input_window_seconds=30, time_conv_size_s=9 / 128, ensure_odd_conv_size=True):\n",
    "#         super(BaseEEGClassifier, self).__init__()\n",
    "\n",
    "#         self.usleep = USleep(\n",
    "#             n_chans=n_chans,\n",
    "#             sfreq=sfreq,\n",
    "#             depth=depth,\n",
    "#             n_time_filters=n_time_filters,\n",
    "#             complexity_factor=complexity_factor,\n",
    "#             with_skip_connection=with_skip_connection,\n",
    "#             n_outputs=n_outputs,\n",
    "#             input_window_seconds=input_window_seconds,\n",
    "#             time_conv_size_s=time_conv_size_s,\n",
    "#             ensure_odd_conv_size=ensure_odd_conv_size\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.usleep(x)\n",
    "#         return x\n",
    "\n",
    "# class EEGClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(EEGClassifier, self).__init__()\n",
    "\n",
    "#         self.base = BaseEEGClassifier()\n",
    "#         self.fc = get_linear(5, 6)  # Adjust based on USleep output features\n",
    "\n",
    "#     def features(self, x):\n",
    "#         x = self.base(x)\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "# # Example usage\n",
    "# model = EEGClassifier()\n",
    "# print(model)\n",
    "\n",
    "\n",
    "class base_args(object):\n",
    "    def __init__(self, model_name, seed=42):\n",
    "        self.model_name = model_name\n",
    "        self.seed = seed\n",
    "\n",
    "        self.lr = 1e-3\n",
    "        self.epochs = 1\n",
    "        self.batch_size = 120\n",
    "        self.num_workers = 2\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.alpha = 0.01\n",
    "        self.phase = \"base\"\n",
    "\n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return f\"{self.model_name}_{self.phase}\"\n",
    "\n",
    "\"\"\"### experiment helper functions\"\"\"\n",
    "\n",
    "def train_model(args, model,\n",
    "          train_data, train_labels,\n",
    "          valid_data, valid_labels,\n",
    "          train_weights=None, sample_rate=None,\n",
    "          use_scheduler=True,\n",
    "          history = {\"Train\": {\"Score\": [], \"Loss\": []},\n",
    "                     \"Valid\": {\"Score\": [], \"Loss\": []}},\n",
    "          mixup_data=None, supervised_mixup_data=None, mixup_idx=None, mixup_rate=None):\n",
    "\n",
    "    train_dataset = SleepDataset(train_data, train_labels, transform=add_noise,\n",
    "                                 mixup_data=mixup_data, supervised_mixup_data=supervised_mixup_data,\n",
    "                                 mixup_idx=mixup_idx, mixup_rate=mixup_rate)\n",
    "\n",
    "    if train_weights is not None:\n",
    "        train_sampler = WeightedRandomSampler(weights = train_weights, num_samples=int(len(train_labels)*sample_rate))\n",
    "        train_loader = DataLoader(train_dataset, num_workers=args.num_workers, batch_size=args.batch_size, sampler=train_sampler, drop_last=True)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    criterion = FocalLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=5e-4)\n",
    "\n",
    "    if use_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                        optimizer,\n",
    "                        max_lr=args.lr,\n",
    "                        epochs=args.epochs,\n",
    "                        steps_per_epoch=len(train_loader),\n",
    "                        div_factor=10,\n",
    "                        final_div_factor=10,\n",
    "                        pct_start=0.1,\n",
    "                        anneal_strategy=\"cos\",\n",
    "                    )\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        _, _, train_score, train_loss = train_epoch(args, model, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        _, _, valid_score, valid_loss = validate_model(args, model, valid_data, valid_labels, show_plot=False)\n",
    "\n",
    "        history[\"Train\"][\"Loss\"].append(train_loss)\n",
    "        history[\"Train\"][\"Score\"].append(train_score)\n",
    "        history[\"Valid\"][\"Loss\"].append(valid_loss)\n",
    "        history[\"Valid\"][\"Score\"].append(valid_score)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{OUTPUT_FOLDER}best_model_{args.get_model_name()}.pt\")\n",
    "\n",
    "\n",
    "def validate_model(args, model, valid_data, valid_labels, desc=\"Target\", show_plot=True):\n",
    "    criterion = FocalLoss()\n",
    "\n",
    "    valid_dataset = SleepDataset(valid_data, valid_labels)\n",
    "    valid_loader = DataLoader(valid_dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)\n",
    "    targets_all, outputs_all, output_score, output_loss = validate(args, model, valid_loader, criterion, desc)\n",
    "\n",
    "    if show_plot:\n",
    "        cf_mat = confusion_matrix(targets_all, np.argmax(outputs_all, axis=1), normalize=\"true\")\n",
    "        plt.figure()\n",
    "        sns.heatmap(cf_mat, annot=True)\n",
    "        plt.show()\n",
    "\n",
    "    return targets_all, outputs_all, output_score, output_loss\n",
    "\n",
    "\n",
    "def get_prediction(args, model, data):\n",
    "    model.to(args.device)\n",
    "    model.load_state_dict(torch.load(f\"{OUTPUT_FOLDER}best_model_{args.get_model_name()}.pt\"))\n",
    "\n",
    "    dataset = SleepDataset(data, None)\n",
    "    loader = DataLoader(dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    output = predict(args, model, loader)\n",
    "    return output\n",
    "\n",
    "\n",
    "def ensemble(args_array, dataset_name=\"test\", phase=None):\n",
    "    ensemble_output = None\n",
    "\n",
    "    for args in args_array:\n",
    "        if phase is None:\n",
    "            fn = f\"{OUTPUT_FOLDER}{args.get_model_name()}-{dataset_name}_output.npy\"\n",
    "        else:\n",
    "            fn = f\"{OUTPUT_FOLDER}{args.model_name}_{phase}-{dataset_name}_output.npy\"\n",
    "\n",
    "        output = np.load(fn)\n",
    "        if ensemble_output is None:\n",
    "            ensemble_output = output\n",
    "        else:\n",
    "            ensemble_output += output\n",
    "\n",
    "    return ensemble_output\n",
    "\n",
    "\n",
    "def predict_and_save(args, model, target_data, test_data):\n",
    "    target_output = get_prediction(args, model, target_data)\n",
    "    np.save(f\"{OUTPUT_FOLDER}{args.get_model_name()}-target_output.npy\", target_output)\n",
    "\n",
    "    test_output = get_prediction(args, model, test_data)\n",
    "    np.save(f\"{OUTPUT_FOLDER}{args.get_model_name()}-test_output.npy\", test_output)\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    fig, axes = plt.subplots(2,1, figsize=(22,6))\n",
    "    axes[0].plot(history[\"Train\"][\"Score\"], label=\"Train score\")\n",
    "    axes[0].plot(history[\"Valid\"][\"Score\"], label=\"Valid score\")\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(history[\"Train\"][\"Loss\"], label=\"Train loss\")\n",
    "    axes[1].plot(history[\"Valid\"][\"Loss\"], label=\"Valid loss\")\n",
    "    axes[1].legend()\n",
    "    fig.show()\n",
    "\n",
    "\"\"\"### competition data loaders\n",
    "\n",
    "### training pipeline function\n",
    "\"\"\"\n",
    "\n",
    "def supervised_run(args, model, train_data, train_labels, target_data, target_labels, test_data, mixup_data=None, supervised_mixup_data=None):\n",
    "    print(args.toJSON())\n",
    "\n",
    "    history = {\"Train\": {\"Score\": [], \"Loss\": []},\n",
    "               \"Valid\": {\"Score\": [], \"Loss\": []}}\n",
    "\n",
    "    ############################\n",
    "    ### USE ONLY SOURCE DATA ###\n",
    "    ############################\n",
    "    args.phase = \"base\"\n",
    "\n",
    "    train_model(args, model,\n",
    "                train_data, train_labels,\n",
    "                target_data, target_labels,\n",
    "                mixup_data=mixup_data, mixup_rate=0.,\n",
    "                history=history)\n",
    "    # validate\n",
    "    model.load_state_dict(torch.load(f\"{OUTPUT_FOLDER}best_model_{args.get_model_name()}.pt\"))\n",
    "    print(\"\\n###### PHASE 1 FINISHED ##########\")\n",
    "    validate_model(args, model, target_data, target_labels, \"Target\")\n",
    "    # make predictions and save results\n",
    "    predict_and_save(args, model, target_data, test_data)\n",
    "\n",
    "\n",
    "    ##############################\n",
    "    ### SOURCE DATA WITH SUPERVISED MIXUP ###\n",
    "    ##############################\n",
    "    args.lr = 1e-4\n",
    "    args.epochs = 1\n",
    "    args.phase = \"mixup\"\n",
    "\n",
    "    train_model(args, model,\n",
    "                train_data, train_labels,\n",
    "                target_data, target_labels,\n",
    "                supervised_mixup_data=supervised_mixup_data, mixup_rate=0.5,\n",
    "                history=history)\n",
    "    # validate\n",
    "    model.load_state_dict(torch.load(f\"{OUTPUT_FOLDER}best_model_{args.get_model_name()}.pt\"))\n",
    "    print(\"\\n###### PHASE 2 FINISHED ########OUTPUT_FOLDER##\")\n",
    "    validate_model(args, model, target_data, target_labels, \"Target\")\n",
    "    # make predictions and save results\n",
    "    predict_and_save(args, model, target_data, test_data)\n",
    "\n",
    "    ###############################\n",
    "    ### FINETUNE ON TARGET DATA WITH MIXED UP SOURCE ###\n",
    "    ###############################\n",
    "    args.lr = 1e-3\n",
    "    args.epochs = 1\n",
    "    args.phase = \"mixup_finetuned\"\n",
    "    # prepare extended train data with sampler settings\n",
    "    extended_train_data = np.concatenate((train_data, target_data), axis=0)\n",
    "    extended_train_labels = np.concatenate((train_labels, target_labels), axis=0)\n",
    "\n",
    "    train_weights = [0.25] * len(train_labels) + [0.75] * len(target_labels)\n",
    "    mixup_idx = [True] * len(train_labels) + [False] * len(target_labels)\n",
    "    train_sample_rate = 0.5\n",
    "\n",
    "    train_model(args, model,\n",
    "                extended_train_data, extended_train_labels,\n",
    "                target_data, target_labels,\n",
    "                train_weights = train_weights, sample_rate=train_sample_rate,\n",
    "                mixup_data=mixup_data, mixup_idx=mixup_idx, mixup_rate=0.5,\n",
    "                use_scheduler=True, history=history)\n",
    "\n",
    "    # validate\n",
    "    model.load_state_dict(torch.load(f\"{OUTPUT_FOLDER}best_model_{args.get_model_name()}.pt\"))\n",
    "    print(\"\\n###### PHASE 3 FINISHED ##########\")\n",
    "    validate_model(args, model, target_data, target_labels, \"Target\")\n",
    "    # make predictions and save results\n",
    "    predict_and_save(args, model, target_data, test_data)\n",
    "    # plot training history\n",
    "    plot_history(history)\n",
    "    \n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Run model training and testing.\")\n",
    "    parser.add_argument('model_file', type=str, help='Path to the model file (e.g., eeg_model.py)')\n",
    "    args = parser.parse_args()\n",
    "    return args.model_file\n",
    "\n",
    "# Function to dynamically load the model from the given file\n",
    "def load_model_from_file(model_file, model_folder='modelpy'):\n",
    "    model_name = os.path.splitext(os.path.basename(model_file))[0]  # Extract model name without extension\n",
    "    model_path = os.path.join(model_folder, model_file)\n",
    "    \n",
    "    # Load the model file dynamically\n",
    "    spec = importlib.util.spec_from_file_location(model_name, model_path)\n",
    "    model_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(model_module)\n",
    "\n",
    "    # Assuming the model file has a class `EEGClassifier`\n",
    "    model_class = getattr(model_module, 'EEGClassifier')\n",
    "    return model_class(), model_name  # Return model instance and model name\n",
    "\n",
    "# Function to run the model training and testing, and save the metadata\n",
    "def run_and_save_model(args, model_name, source_data, source_labels, target_data, target_labels, test_data,test_labels, mixup_data=None, supervised_mixup_data=None):\n",
    "    # Load the model dynamically from the specified file\n",
    "    model, model_base_name = load_model_from_file(model_name)\n",
    "\n",
    "    # Create a folder to save the model and training details\n",
    "    model_dir = os.path.join(OUTPUT_FOLDER, \"models\", model_base_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Define the output metadata file\n",
    "    meta_file_path = os.path.join(model_dir, f\"{model_base_name}_output_meta.txt\")\n",
    "\n",
    "    # Track start time for training\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Call the existing supervised_run function (no modifications)\n",
    "    supervised_run(args, model, source_data, source_labels, target_data, target_labels, test_data, mixup_data=mixup_data, supervised_mixup_data=supervised_mixup_data)\n",
    "\n",
    "    # Calculate and save training time\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    train_time_str = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(train_time))\n",
    "    print(f\"Training completed in: {train_time_str}\")\n",
    "\n",
    "    # Save the training time and details to the metadata file\n",
    "    with open(meta_file_path, \"w\") as f:\n",
    "        f.write(f\"Training time: {train_time_str}\\n\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, f\"{model_base_name}_final_model.pt\"))\n",
    "\n",
    "    # Track start time for testing/validation\n",
    "    start_test_time = time.time()\n",
    "\n",
    "    # Validate and save predictions (already done in supervised_run)\n",
    "    # Capture validation and test accuracy\n",
    "    valid_score, test_score = validate_and_test(args, model, target_data, target_labels, test_data,test_labels)\n",
    "\n",
    "    # Calculate and save testing time\n",
    "    end_test_time = time.time()\n",
    "    test_time = end_test_time - start_test_time\n",
    "    test_time_str = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(test_time))\n",
    "    print(f\"Testing completed in: {test_time_str}\")\n",
    "\n",
    "    # Save the testing time, accuracies, and losses to the metadata file\n",
    "    with open(meta_file_path, \"a\") as f:\n",
    "        f.write(f\"Testing time: {test_time_str}\\n\")\n",
    "        f.write(f\"Validation Accuracy: {valid_score:.2f}\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_score:.2f}\\n\")\n",
    "\n",
    "    # Print accuracies explicitly\n",
    "    print(f\"Validation Accuracy: {valid_score:.2f}\")\n",
    "    print(f\"Test Accuracy: {test_score:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_test_accuracy(predictions, true_labels):\n",
    "    # \"\"\"\n",
    "    # Calculate accuracy by comparing predictions to the true labels using scikit-learn.\n",
    "    # Arguments:\n",
    "    # - predictions: Model predictions (e.g., class probabilities or logits)\n",
    "    # - true_labels: Actual class labels\n",
    "\n",
    "    # Returns:\n",
    "    # - accuracy: Calculated accuracy as a percentage\n",
    "    # \"\"\"\n",
    "    # # Convert predictions to a tensor if it's a NumPy array\n",
    "    # if isinstance(predictions, np.ndarray):\n",
    "    #     predictions = torch.tensor(predictions)\n",
    "    \n",
    "    # # Convert true_labels to a tensor if it's a NumPy array\n",
    "    # if isinstance(true_labels, np.ndarray):\n",
    "    #     true_labels = torch.tensor(true_labels)\n",
    "\n",
    "    # # If predictions are multi-dimensional (e.g., probabilities or logits), get the class predictions\n",
    "    # if predictions.dim() > 1:\n",
    "    #     predicted_classes = torch.argmax(predictions, dim=1).numpy()  # Convert to numpy array\n",
    "    # else:\n",
    "    #     predicted_classes = predictions.numpy()  # Convert to numpy array\n",
    "\n",
    "    # true_labels = true_labels.numpy()  # Convert to numpy array\n",
    "\n",
    "    # # Calculate accuracy using scikit-learn's accuracy_score\n",
    "    accuracy = accuracy_score(true_labels, predictions) * 100  # Convert to percentage\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validate_and_test(args, model, target_data, target_labels, test_data,test_labels):\n",
    "    \"\"\"\n",
    "    Function to handle validation and test, returning their accuracies.\n",
    "    \"\"\"\n",
    "    # Validate\n",
    "    _, _, valid_score, _ = validate_model(args, model, target_data, target_labels, \"Target\")\n",
    "\n",
    "    # Test (Using predict_and_save if it also returns test accuracy)\n",
    "    test_output = get_prediction(args, model, test_data)\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(type(test_labels))\n",
    "    print(type(test_output))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    test_accuracy = calculate_test_accuracy(test_labels, test_output)\n",
    "\n",
    "    return valid_score, test_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"### training\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load train data and labels\n",
    "source_data = np.load('/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/data/train/data.npy')\n",
    "source_labels = np.load('/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/data/train/labels.npy')\n",
    "\n",
    "# Load validate data and labels\n",
    "target_data = np.load('/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/data/validate/data.npy')\n",
    "target_labels = np.load('/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/data/validate/labels.npy')\n",
    "\n",
    "# Load test data and labels\n",
    "test_data = np.load('/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/data/test/data.npy')\n",
    "test_labels = np.load('/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/model_final/data/test/labels.npy')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_train is your array\n",
    "unique_classes, counts = np.unique(target_labels, return_counts=True)\n",
    "\n",
    "# Calculating the total number of entries\n",
    "total_entries = counts.sum()\n",
    "\n",
    "# Creating a dictionary to show class: percentage of entries\n",
    "class_percentages = {cls: (count / total_entries) * 100 for cls, count in zip(unique_classes, counts)}\n",
    "print(class_percentages)\n",
    "\n",
    "# mixup_data\n",
    "\n",
    "tmp = np.array(target_data)\n",
    "supervised_mixup_data = {}\n",
    "for c in np.unique(target_labels):\n",
    "    supervised_mixup_data[c] = tmp[target_labels == c]\n",
    "    print(c, np.shape(supervised_mixup_data[c]))\n",
    "\n",
    "del tmp\n",
    "\n",
    "\n",
    "# Print the shape of each\n",
    "print(\"Train data shape:\", source_data.shape)\n",
    "print(\"Train labels shape:\", source_labels.shape)\n",
    "print(\"Validate data shape:\", target_data.shape)\n",
    "print(\"Validate labels shape:\", target_labels.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)\n",
    "\n",
    "# Calculate and print total data size (total number of samples)\n",
    "total_data_size = source_labels.shape[0] + target_data.shape[0] + test_data.shape[0]\n",
    "print(\"Total data size (number of samples):\", total_data_size)\n",
    "\n",
    "\n",
    "\n",
    "# Main runner function\n",
    "if __name__ == \"__main__\":\n",
    "    # Parse model file argument from command-line\n",
    "    # model_file = parse_args()\n",
    "    model_file = \"eeg_model.py\"\n",
    "    # Example usage\n",
    "    args_array = []\n",
    "    args = base_args(\"eeg-classifier_seed-42\")\n",
    "    seed_everything(args.seed)\n",
    "\n",
    "    # Call the new function that tracks time and saves the model using the model file name from the argument\n",
    "    run_and_save_model(args, model_file, source_data, source_labels, target_data, target_labels, test_data,test_labels, mixup_data=None, supervised_mixup_data=supervised_mixup_data)\n",
    "\n",
    "    # Append the arguments to the array for later reference\n",
    "    args_array.append(args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29807c-7fbe-49a0-b017-c07effe84196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceae00d-ecf3-4a7d-b8a0-f168fc54fc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
