{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca9336c7-d5b2-4c56-8b59-a04f48101a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/SleepSource/ (158 files) - Load labels True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████▏                                                                                                     | 13/158 [00:00<00:01, 115.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: Fpz-Cz, Pz-Oz\n",
      " chs: 2 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.5 Hz\n",
      " lowpass: 100.0 Hz\n",
      " meas_date: 1991-09-26 15:00:00 UTC\n",
      " nchan: 2\n",
      " projs: []\n",
      " sfreq: 100.0 Hz\n",
      " subject_info: 2 items (dict)\n",
      ">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 158/158 [00:01<00:00, 95.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded total 90545 samples for subjects: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 4197.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source mean: -2.175762164676705e-07, std: 1.6836217270029333e-05, min: -14.7172265485441, max: 12.426637935405019\n",
      "Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/LeaderboardSleep/sleep_target/ (25 files) - Load labels True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████████████▍                                                                             | 8/25 [00:00<00:00, 75.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: Fpz-Cz, Pz-Oz\n",
      " chs: 2 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.5 Hz\n",
      " lowpass: 100.0 Hz\n",
      " meas_date: 1990-03-13 15:09:00 UTC\n",
      " nchan: 2\n",
      " projs: []\n",
      " sfreq: 100.0 Hz\n",
      " subject_info: 2 items (dict)\n",
      ">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 84.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded total 15442 samples for subjects: [0 1 2 3 4 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 5197.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leadeboard target mean: 0.038902552623313796, std: 1.0560441229752748, min: -11.688042547053058, max: 12.010867582259191\n",
      "Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/LeaderboardSleep/testing/ (25 files) - Load labels False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 50.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded total 25748 samples for subjects: [ 6  7  8  9 10 11 12 13 14 15 16 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 7412.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leadeboard test mean: 0.014119353426048422, std: 0.8645048345254686, min: -11.985021370728651, max: 11.832680288053835\n",
      "Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/finalSleep/sleep_target/ (20 files) - Load labels True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 57.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded total 16568 samples for subjects: [0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 4041.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final target mean: 0.023971523471475097, std: 0.8755512574787386, min: -11.866229841258413, max: 11.892076052788953\n",
      "Loading data from folder: /home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/finalSleep/testing/ (18 files) - Load labels False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded total 25756 samples for subjects: [ 5  6  7  8  9 10 11 12 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 5787.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test mean: 0.04296289931340894, std: 0.8598280113936251, min: -12.282000194404242, max: 11.713888758583598\n",
      "0 (24043, 2, 3000)\n",
      "1 (7941, 2, 3000)\n",
      "2 (35983, 2, 3000)\n",
      "3 (5247, 2, 3000)\n",
      "4 (3057, 2, 3000)\n",
      "5 (14274, 2, 3000)\n",
      "Directory created: data/train\n",
      "Directory created: data/validate\n",
      "Directory created: data/test\n",
      "Saved train data to data/train/data.npy and labels to data/train/labels.npy\n",
      "Saved validate data to data/validate/data.npy and labels to data/validate/labels.npy\n",
      "Saved test data to data/test/data.npy and labels to data/test/labels.npy\n",
      "All variables saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_FOLDER ='/home/deepak/Documents/Deepak/Students/Susmit_23CS60R75/Sleep_Data/'\n",
    "SOURCE_DATA_FOLDER = DATA_FOLDER  + \"SleepSource/\"\n",
    "LEADERBOARD_TARGET_DATA_FOLDER = DATA_FOLDER + \"LeaderboardSleep/sleep_target/\"\n",
    "LEADERBOARD_TEST_DATA_FOLDER = DATA_FOLDER + \"LeaderboardSleep/testing/\"\n",
    "FINAL_TARGET_DATA_FOLDER = DATA_FOLDER + \"finalSleep/sleep_target/\"\n",
    "FINAL_TEST_DATA_FOLDER = DATA_FOLDER + \"finalSleep/testing/\"\n",
    "\n",
    "\n",
    "\n",
    "def load_data(data_folder, load_labels=True):\n",
    "    fn_list = sorted(os.listdir(data_folder))\n",
    "    print(f\"Loading data from folder: {data_folder} ({len(fn_list)} files) - Load labels {load_labels}\")\n",
    "\n",
    "    data_map = {}\n",
    "    subject_list = []\n",
    "    sample_counter = 0\n",
    "\n",
    "    for fn in tqdm(fn_list):\n",
    "        if fn.endswith(\"X.npy\"):\n",
    "            code = fn.split(\"_\")[1][:-4]\n",
    "        elif fn == \"headerInfo.npy\":\n",
    "            meta = np.load(data_folder + fn, allow_pickle=True)\n",
    "            print(meta)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        eeg = np.load(data_folder + fn, allow_pickle=True)\n",
    "\n",
    "        if load_labels:\n",
    "            label_fn = fn.replace(\"X\", \"y\")\n",
    "            label = np.load(data_folder + label_fn, allow_pickle=True)\n",
    "        else:\n",
    "            label = None\n",
    "\n",
    "        s_part, r_part = code.split(\"r\")\n",
    "        subject = int(s_part[1:])\n",
    "        repetition = int(r_part[:-1])\n",
    "\n",
    "        subject_list.append(subject)\n",
    "\n",
    "        if subject not in data_map.keys():\n",
    "            data_map[subject] = {}\n",
    "\n",
    "        data_map[subject][repetition] = {\"eeg\": eeg, \"label\": label}\n",
    "        sample_counter += len(eeg)\n",
    "\n",
    "    subject_list = np.unique(subject_list)\n",
    "    print(f\"Loaded total {sample_counter} samples for subjects: {subject_list}\")\n",
    "    return data_map, subject_list\n",
    "\n",
    "def prepare_window_data(data, subject_list=None):\n",
    "    window_data = []\n",
    "    window_labels = []\n",
    "\n",
    "    if subject_list is None:\n",
    "        subject_list = data.keys()\n",
    "\n",
    "    for s in tqdm(subject_list):\n",
    "        for r in data[s].keys():\n",
    "            eeg = data[s][r][\"eeg\"]\n",
    "            label = data[s][r][\"label\"]\n",
    "\n",
    "            window_data.extend(eeg)\n",
    "\n",
    "            if label is not None:\n",
    "                window_labels.extend(label)\n",
    "\n",
    "    return window_data, window_labels\n",
    "\n",
    "def print_stats(desc, data):\n",
    "    print(f\"{desc} mean: {np.mean(data)}, std: {np.std(data)}, min: {np.min(data)}, max: {np.max(data)}\")\n",
    "\n",
    "def normalize(data, mean_value, std_value, desc=\"\"):\n",
    "    data = np.array(data)\n",
    "    data = (data - mean_value) / std_value\n",
    "    print_stats(desc, data)\n",
    "    return list(data)\n",
    "\n",
    "# def filter_freq(data, f_min, f_max, FS):\n",
    "#     return mne.filter.filter_data(np.array(data, dtype=np.float64), FS, f_min, f_max, method=\"iir\", verbose=False)\n",
    "\n",
    "# def downsample(data, FS, FS_new):\n",
    "#     return mne.filter.resample(data, down=FS/FS_new)\n",
    "\n",
    "\n",
    "\n",
    "# def seed_everything(seed):\n",
    "#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def get_phase_1_data():\n",
    "    source_data, source_subjects = load_data(SOURCE_DATA_FOLDER)\n",
    "    source_data, source_labels = prepare_window_data(source_data, source_subjects)\n",
    "    # calculate stats of source data and normalize it\n",
    "    source_data = np.array(source_data)\n",
    "    source_mean = np.mean(source_data)\n",
    "    source_std = np.std(source_data)\n",
    "    source_data = (source_data - source_mean) / source_std\n",
    "    print(f\"Source mean: {source_mean}, std: {source_std}, min: {np.min(source_data)}, max: {np.max(source_data)}\")\n",
    "    source_data  = list(source_data)\n",
    "    # load and normalize target data\n",
    "    lb_target_data, lb_target_subjects = load_data(LEADERBOARD_TARGET_DATA_FOLDER)\n",
    "    lb_target_data, lb_target_labels = prepare_window_data(lb_target_data, lb_target_subjects)\n",
    "    lb_target_data = normalize(lb_target_data, source_mean, source_std, \"Leadeboard target\")\n",
    "    # load and normalize test data\n",
    "    lb_test_data, lb_test_subjects = load_data(LEADERBOARD_TEST_DATA_FOLDER, load_labels=False)\n",
    "    lb_test_data, lb_test_labels = prepare_window_data(lb_test_data, lb_test_subjects)\n",
    "    lb_test_data = normalize(lb_test_data, source_mean, source_std, \"Leadeboard test\")\n",
    "    \n",
    "        # load and normalize target data\n",
    "    fn_target_data, fn_target_subjects = load_data(FINAL_TARGET_DATA_FOLDER)\n",
    "    fn_target_data, fn_target_labels = prepare_window_data(fn_target_data, fn_target_subjects)\n",
    "    fn_target_data = normalize(fn_target_data, source_mean, source_std, \"Final target\")\n",
    "    # load and normalize test data\n",
    "    fn_test_data, fn_test_subjects = load_data(FINAL_TEST_DATA_FOLDER, load_labels=False)\n",
    "    fn_test_data, fn_test_labels = prepare_window_data(fn_test_data, fn_test_subjects)\n",
    "    fn_test_data = normalize(fn_test_data, source_mean, source_std, \"Final test\")\n",
    "\n",
    "    return source_data, source_labels, lb_target_data, lb_target_labels, lb_test_data, lb_test_data,fn_target_data, fn_target_labels ,fn_test_data, fn_test_labels\n",
    "\n",
    "\n",
    "\n",
    "def split_train_val_test(train_data, train_labels, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # First, split into training and temp (validation + test)\n",
    "    train_data_split, temp_data, train_labels_split, temp_labels = train_test_split(\n",
    "        train_data, train_labels, train_size=train_size, random_state=random_state, stratify=train_labels\n",
    "    )\n",
    "\n",
    "    # Calculate the proportion of validation and test sizes relative to temp_data\n",
    "    temp_val_size = val_size / (val_size + test_size)\n",
    "    val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "        temp_data, temp_labels, test_size=1 - temp_val_size, random_state=random_state, stratify=temp_labels\n",
    "    )\n",
    "\n",
    "    return train_data_split, val_data, test_data, train_labels_split, val_labels, test_labels\n",
    "\n",
    "def create_data_directories(base_dir='data', subdirs=['train', 'validate', 'test']):\n",
    "    for subdir in subdirs:\n",
    "        path = os.path.join(base_dir, subdir)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        print(f\"Directory created: {path}\")\n",
    "\n",
    "def save_splits(base_dir, splits):\n",
    "    \"\"\"\n",
    "    Saves the data and labels into respective directories.\n",
    "\n",
    "    Parameters:\n",
    "    - base_dir: The main directory containing subdirectories.\n",
    "    - splits: A tuple containing (train_data, val_data, test_data, train_labels, val_labels, test_labels).\n",
    "    \"\"\"\n",
    "    train_data, val_data, test_data, train_labels, val_labels, test_labels = splits\n",
    "    splits_dict = {\n",
    "        'train': (train_data, train_labels),\n",
    "        'validate': (val_data, val_labels),\n",
    "        'test': (test_data, test_labels)\n",
    "    }\n",
    "\n",
    "    for split_name, (data, labels) in splits_dict.items():\n",
    "        data_path = os.path.join(base_dir, split_name, 'data.npy')\n",
    "        labels_path = os.path.join(base_dir, split_name, 'labels.npy')\n",
    "        np.save(data_path, data)\n",
    "        np.save(labels_path, labels)\n",
    "        print(f\"Saved {split_name} data to {data_path} and labels to {labels_path}\")\n",
    "\n",
    "def save_remaining_variables():\n",
    "    # Create necessary directories\n",
    "    directories = ['data/leader', 'data/final']\n",
    "    for directory in directories:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "    # Save leaderboard data\n",
    "    np.save('data/leader/lbtarget_data.npy', lb_target_data)\n",
    "    np.save('data/leader/lbtarget_labels.npy', lb_target_labels)\n",
    "    np.save('data/leader/test_data.npy', lb_test_data)\n",
    "    np.save('data/leader/test_data_cpy.npy', lb_test_data_cpy)\n",
    "\n",
    "    # Save final data\n",
    "    np.save('data/final/fntarget_data.npy', fn_target_data)\n",
    "    np.save('data/final/fntarget_labels.npy', fn_target_labels)\n",
    "    np.save('data/final/test_data.npy', fn_test_data)\n",
    "    np.save('data/final/test_data_cpy.npy', fn_test_data_cpy)\n",
    "\n",
    "    print(\"All variables saved successfully.\")\n",
    "\n",
    "\n",
    "source_data, source_labels, lb_target_data, lb_target_labels, lb_test_data, lb_test_data_cpy, fn_target_data, fn_target_labels, fn_test_data, fn_test_data_cpy= get_phase_1_data()\n",
    "\n",
    "tmp = np.array(source_data)\n",
    "supervised_mixup_data = {}\n",
    "for c in np.unique(source_labels):\n",
    "    supervised_mixup_data[c] = tmp[source_labels == c]\n",
    "    print(c, np.shape(supervised_mixup_data[c]))\n",
    "\n",
    "del tmp\n",
    "\n",
    "splits = split_train_val_test(source_data, source_labels)\n",
    "create_data_directories()\n",
    "save_splits('data', splits)\n",
    "save_remaining_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3b399-b048-470a-8fcb-6dd18d625141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
